{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a8c7860",
   "metadata": {},
   "source": [
    "# Priyanka Vinod Thesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9669c94",
   "metadata": {},
   "source": [
    "#### Load all packages and functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97054670",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import all packages\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from scipy.stats import mode\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "from keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from keras.losses import binary_crossentropy\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.layers import Dense, Dropout, LSTM, GRU \n",
    "from sklearn.model_selection import RepeatedStratifiedKFold \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import auc, f1_score, roc_curve, accuracy_score, roc_auc_score, balanced_accuracy_score, precision_recall_curve, confusion_matrix, classification_report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd28acdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load OpenFace data and return a dataframe \n",
    "def load_OF_data(path):\n",
    "    df = pd.read_csv(path, index_col = 0) \n",
    "    print('Dimensions of OpenFace data from R:', df.shape)\n",
    "    print('Column names of OpenFace data from R:\\n', list(df))\n",
    "    return df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e568461f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load FaceReader data and return a dataframe \n",
    "def load_FR_data(path):\n",
    "    df = pd.read_csv(path, index_col = 0) \n",
    "    print('\\nDimensions of FaceReader data from R:', df.shape)\n",
    "    print('Column names of FaceReader data from R:\\n', list(df))\n",
    "    return df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84b5faea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load survey data and return a dataframe\n",
    "def load_survey_data(path):\n",
    "    df = pd.read_csv(path, delimiter = ';') \n",
    "    print('\\nSurvey data: \\n', df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb8720bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## process the survey data\n",
    "def survey_process(df):\n",
    "    a = df['index']\n",
    "    b = df['pinv']\n",
    "    return a, b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "814bb08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## split the entire df into cumulative (features+labels) train and test parts by index-matching\n",
    "def get_rows(trn_ind, tst_ind, of_data):\n",
    "    df_trn = of_data[of_data['index'].isin(trn_ind)]\n",
    "    df_tst = of_data[of_data['index'].isin(tst_ind)]  \n",
    "    return df_trn, df_tst "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95609b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "## split the cumulative train and test parts into 4 train and test parts (features and labels respectively) \n",
    "def get_train_test_dfs(df_trn, df_tst):\n",
    "    y_train = df_trn['y']\n",
    "    y_test = df_tst['y']\n",
    "    cols = ['y', 'index']\n",
    "    X_train = df_trn.drop(cols, axis = 1)   \n",
    "    X_test = df_tst.drop(cols, axis = 1)   \n",
    "    return X_train, X_test, y_train, y_test   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2efaafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove used indices to ensure indices do not overlap\n",
    "def new_ind_pinv(index, pinv, trn):\n",
    "    df = pd.concat([index, pinv], axis = 1)\n",
    "    data = df[df['index'].isin(trn.tolist())]\n",
    "    return data['index'], data['pinv']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5171503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## setting up the parameter grids for HP tuning\n",
    "def parameter_grid(timestep, features):\n",
    "    grid = [{'units': [32, 64, 128, 256],                   \n",
    "             'dropout': [0.2, 0.3, 0.4, 0.5],                 \n",
    "             'epochs': [50, 75, 100],                     \n",
    "             'batch_size': [16, 32, 64],   \n",
    "             'rate': [0.01, 0.001, 0.0001],\n",
    "             'timestep': [timestep],\n",
    "             'features': [features]}]    \n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fff40222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up multiple GridSearchCV objects, 1 for each algorithm (we have 2 for LSTM and GRU)\n",
    "def grid_search_objects(grid):\n",
    "    gridcvs = {}\n",
    "    inner_cv = RepeatedStratifiedKFold(n_splits = 2, n_repeats = 2, random_state = None) \n",
    "\n",
    "    model1 = KerasClassifier(build_fn = base_GRU) \n",
    "    model2 = KerasClassifier(build_fn = base_LSTM) \n",
    "             \n",
    "    for pgrid, est, name in zip((grid, grid), \n",
    "                                (model1, model2), \n",
    "                                ('GRU', 'LSTM')):  \n",
    "        gcv = GridSearchCV(estimator = est,\n",
    "                           param_grid = pgrid,\n",
    "                           scoring = 'accuracy',\n",
    "                           n_jobs = -1,\n",
    "                           cv = inner_cv,\n",
    "                           verbose = 0,\n",
    "                           refit = True, \n",
    "                           return_train_score = True)\n",
    "        gridcvs[name] = gcv\n",
    "    return gridcvs, inner_cv   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08c5ca4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## scale train and test data to range [0, 1] \n",
    "def scale_data(train, test): \n",
    "    scaler = MinMaxScaler()\n",
    "    train_scaled = scaler.fit_transform(train.values)\n",
    "    test_scaled = scaler.transform(test.values)\n",
    "    return train_scaled, test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a75a82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## find mode for reshaped labels\n",
    "def find_mode(data):\n",
    "    m = mode(data, axis = 1)\n",
    "    return m[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87457707",
   "metadata": {},
   "outputs": [],
   "source": [
    "## reshape data\n",
    "def reshape_data(X_train, X_test, y_train, y_test, timestep):\n",
    "    sample1 = int(X_train.shape[0]/timestep)\n",
    "    sample2 = int(X_test.shape[0]/timestep)\n",
    "    features = X_train.shape[1]\n",
    "    X_train = X_train.reshape(sample1, timestep, features)\n",
    "    X_test = X_test.reshape(sample2, timestep, features)\n",
    "    y_train = y_train.values.reshape(sample1, timestep)\n",
    "    y_train = find_mode(y_train)\n",
    "    y_test = y_test.values.reshape(sample2, timestep)\n",
    "    y_test = find_mode(y_test)   \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01c47b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define GRU model \n",
    "def base_GRU(units = 32, dropout = 0.2, rate = 0.001, timestep = 100, features = 16):\n",
    "    model =  Sequential()\n",
    "    model.add(GRU(units, input_shape = (timestep, features)))  \n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "    # compile model\n",
    "    opt = Adam(learning_rate = rate)\n",
    "    model.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b001156",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define LSTM model \n",
    "def base_LSTM(units = 32, dropout = 0.2, rate = 0.001, timestep = 100, features = 16):\n",
    "    model =  Sequential()\n",
    "    model.add(LSTM(units, input_shape = (timestep, features))) \n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "    # compile model\n",
    "    opt = Adam(lr = rate)\n",
    "    model.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3367521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(y_true, y_pred):  \n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    bacc = balanced_accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    target_names = ['No', 'Yes']\n",
    "    cr = classification_report(y_true, y_pred, target_names = target_names)\n",
    "    roc = roc_auc_score(y_true, y_pred)\n",
    "    return acc, bacc, f1, cm, cr, roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51d88617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(cm):\n",
    "    plt.figure(figsize = (5, 5))\n",
    "    ax = plt.subplot()\n",
    "    sns.heatmap(cm, annot = True, fmt = \".0f\", linewidths = .5, square = True, cmap = 'Blues_r', ax = ax);\n",
    "    ax.set_ylabel('True labels'); \n",
    "    ax.set_xlabel('Predicted labels');\n",
    "    ax.xaxis.set_ticklabels(['No', 'Yes']); \n",
    "    ax.yaxis.set_ticklabels(['No', 'Yes']);\n",
    "    plt.title('Confusion Matrix ', size = 15);\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6c8606b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_plot(lr_probs, y_true, name):\n",
    "    # generate a no skill prediction (majority class)\n",
    "    ns_probs = [0 for _ in range(len(y_true))]\n",
    "    # keep probabilities for the positive outcome only\n",
    "    lr_probs = lr_probs[:, 1]\n",
    "    # calculate scores\n",
    "    ns_auc = roc_auc_score(y_true, ns_probs)\n",
    "    lr_auc = roc_auc_score(y_true, lr_probs)\n",
    "    # summarize scores\n",
    "    print('        ROC AUC = %.3f' % (lr_auc))\n",
    "    ns_fpr, ns_tpr, _ = roc_curve(y_true, ns_probs)\n",
    "    lr_fpr, lr_tpr, _ = roc_curve(y_true, lr_probs)\n",
    "    plt.plot(ns_fpr, ns_tpr, linestyle = '--', label = 'No Skill')\n",
    "    plt.plot(lr_fpr, lr_tpr, marker = '.', label = name)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cd43114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prc_plot(lr_probs, y_true, y_pred, name):\n",
    "    # generate a no skill prediction (majority class)\n",
    "    ns_probs = [0 for _ in range(len(y_true))]\n",
    "    # keep probabilities for the positive outcome only\n",
    "    lr_probs = lr_probs[:, 1]\n",
    "    # calculate scores\n",
    "    lr_precision, lr_recall, _ = precision_recall_curve(y_true, lr_probs)\n",
    "    lr_f1, lr_auc = f1_score(y_true, y_pred), auc(lr_recall, lr_precision)\n",
    "    # summarize scores\n",
    "    print('        F1-score = %.3f, PRC AUC = %.3f' % (lr_f1, lr_auc))\n",
    "    # plot the precision-recall curves\n",
    "    no_skill = len(y_true[y_true == 1]) / len(y_true)\n",
    "    plt.plot([0, 1], [no_skill, no_skill], linestyle = '--', label = 'No Skill')\n",
    "    plt.plot(lr_recall, lr_precision, marker = '.', label = name)\n",
    "    # axis labels\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('PRC Curve')\n",
    "    # show the legend\n",
    "    plt.legend()\n",
    "    # show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbbd3918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_combined(tprs, aucs, mean_fpr, i):\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', label='No skill')\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    plt.plot(mean_fpr, mean_tpr, label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc))\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2, label=r'$\\pm$ 1 std. dev.')\n",
    "    plt.xlim([-0.01, 1.01])\n",
    "    plt.ylim([-0.01, 1.01])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Cross-Validation ROC')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cee5c2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## implement stratified k-fold nested cross validation \n",
    "def nested_stratifiedKfold(index, pinv, data, gridcvs, inner_cv, timestep):\n",
    "    for name, gs_est in sorted(gridcvs.items()):\n",
    "        print('\\nAlgorithm:', name, '\\n')\n",
    "        print('    Details for each fold of outer loop:\\n')\n",
    "    \n",
    "        outer_ascores_segment = []\n",
    "        outer_ascores_video = []\n",
    "        outer_fscores_segment = []\n",
    "        outer_fscores_video = []\n",
    "        outer_cm_segment = []\n",
    "        outer_cm_video = []\n",
    "        outer_roc_segment = []\n",
    "        outer_roc_video = []\n",
    "        tprs = []\n",
    "        aucs = []\n",
    "        mean_fpr = np.linspace(0, 1, 100)\n",
    "        i = 0\n",
    "        fold = 1\n",
    "        gridlst = []\n",
    "                \n",
    "        outer_cv = RepeatedStratifiedKFold(n_splits = 4, n_repeats = 1, random_state = None)  #shuffle = True,  \n",
    "                \n",
    "        for train_index, test_index in outer_cv.split(index, pinv):\n",
    "            print('        Fold', fold, '/ 4')\n",
    "            i_trn, i_tst = index.iloc[train_index], index.iloc[test_index]\n",
    "            p_trn, p_tst = pinv.iloc[train_index], pinv.iloc[test_index]\n",
    "            print('        Startup indices used for training:', i_trn.values, '\\n'\n",
    "                  '        Startup indices used for testing:', i_tst.values)\n",
    "                       \n",
    "            df_trn, df_tst = get_rows(i_trn, i_tst, data)\n",
    "            xtrain, xtest, ytrain, ytest = get_train_test_dfs(df_trn, df_tst)\n",
    "            XX_train, XX_test = scale_data(xtrain, xtest)        \n",
    "            \n",
    "            ## just to verify indices used for HP tuning; ignore this\n",
    "            print('        Startup indices used for hyperparameter tuning:')\n",
    "            index_new, pinv_new = new_ind_pinv(index, pinv, i_trn.values)\n",
    "            for train_index, test_index in inner_cv.split(index_new, pinv_new):\n",
    "                i_trn, i_tst = index_new.iloc[train_index], index_new.iloc[test_index]\n",
    "                print('          Training:', i_trn.values, '\\n'\n",
    "                      '          Validation:', i_tst.values)\n",
    "            ## end of code     \n",
    "                \n",
    "            X_train, X_test, y_train, y_test = reshape_data(XX_train, XX_test, ytrain, ytest, timestep)            \n",
    "            print('\\n        Dimensions of train and test data (features):', X_train.shape, ',', X_test.shape)\n",
    "            print('        Dimensions of train and test data (targets):', y_train.shape, ',', y_test.shape, '\\n')\n",
    "            \n",
    "            ## fitting the model\n",
    "            time_start = time.time()\n",
    "            gridcvs[name].fit(X_train, y_train, verbose = 1)  \n",
    "            \n",
    "            print(\"        Time taken for training:\", str(round(time.time() - time_start, 2)) + \"s\")\n",
    "            print('        Best hyperparameters found for current fold:\\n', '        ', gridcvs[name].best_params_, '\\n')\n",
    "            y_true = y_test\n",
    "            y_pred = gridcvs[name].predict(X_test)\n",
    "            lr_probs = gridcvs[name].predict_proba(X_test)            \n",
    "                \n",
    "            ## plot roc and prc curves\n",
    "            roc_plot(lr_probs, y_true, name)\n",
    "            prc_plot(lr_probs, y_true, y_pred, name)\n",
    "            # for combined roc curve\n",
    "            fpr, tpr, _ = roc_curve(y_true, lr_probs[:, 1])\n",
    "            tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "            tprs[-1][0] = 0.0\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            aucs.append(roc_auc)\n",
    "                                       \n",
    "            ## calculating scores\n",
    "            acc, bacc, fscore, cm, cr, roc = scores(y_true, y_pred) #, lr_probs)\n",
    "            print('        Segment-level test accuracy: %.2f%%' % (100 * acc)) \n",
    "            outer_ascores_segment.append(acc) \n",
    "            print('        Segment-level balanced accuracy: %.2f%%' % (100 * bacc))\n",
    "            print('        Segment-level F1-score: %.2f%%' % (100 * fscore))    \n",
    "            outer_fscores_segment.append(fscore) \n",
    "            print('        Segment-level ROC-AUC score: %.2f%%' % (100 * roc))    \n",
    "            outer_roc_segment.append(roc) \n",
    "            print('        Confusion matrix:\\n')\n",
    "            outer_cm_segment.append(cm)\n",
    "            plot_cm(cm)\n",
    "            print('        Classification report:\\n', cr)\n",
    "            \n",
    "            count_test = 6                     # count of test videos                      \n",
    "            s = int(y_test.shape[0]/count_test)                  \n",
    "            p = mode(y_true.reshape(count_test, s), axis = 1)\n",
    "            q = mode(y_pred.reshape(count_test, s), axis = 1) \n",
    "            acc, bacc, fscore, cm, cr, roc = scores(p[0], q[0])   \n",
    "            print('        Video-level test accuracy: %.2f%%' % (100 * acc))\n",
    "            outer_ascores_video.append(acc)\n",
    "            print('        Video-level balanced accuracy: %.2f%%' % (100 * bacc))\n",
    "            print('        Video-level F1-score: %.2f%%' % (100 * fscore))\n",
    "            outer_fscores_video.append(fscore)\n",
    "            print('        Video-level ROC-AUC score: %.2f%%' % (100 * roc))\n",
    "            outer_roc_video.append(roc)\n",
    "            print('        Confusion matrix:\\n')\n",
    "            outer_cm_video.append(cm)\n",
    "            plot_cm(cm)\n",
    "            print('        Classification report:\\n', cr) \n",
    "            print('       ', 100 * '*', '\\n')\n",
    "            \n",
    "            fold += 1\n",
    "            i += 1\n",
    "                \n",
    "        print('\\n    Average accuracy over all folds:')\n",
    "        print('        Segment-level accuracy %.2f%% (%.2f)' % (np.mean(outer_ascores_segment) * 100, \n",
    "                                                       np.std(outer_ascores_segment) * 100)) \n",
    "        print('        Video-level accuracy %.2f%% (%.2f)' % (np.mean(outer_ascores_video) * 100, \n",
    "                                                     np.std(outer_ascores_video) * 100))  \n",
    "        print('\\n    Average F1-score over all folds:')\n",
    "        print('        Segment-level F1-score %.2f%% (%.2f)' % (np.mean(outer_fscores_segment) * 100, \n",
    "                                                       np.std(outer_fscores_segment) * 100)) \n",
    "        print('        Video-level F1-score %.2f%% (%.2f)' % (np.mean(outer_fscores_video) * 100, \n",
    "                                                     np.std(outer_fscores_video) * 100)) \n",
    "        print('\\n    Average ROC-AUC score over all folds:')\n",
    "        print('        Segment-level ROC-AUC score %.2f%% (%.2f)' % (np.mean(outer_roc_segment) * 100, \n",
    "                                                       np.std(outer_roc_segment) * 100)) \n",
    "        print('        Video-level ROC-AUC score %.2f%% (%.2f)' % (np.mean(outer_roc_video) * 100, \n",
    "                                                     np.std(outer_roc_video) * 100)) \n",
    "        print('\\n    Confusion matrix over all folds:')\n",
    "        print('        Segment-level CM: \\n')        \n",
    "        avg_cm = np.mean(outer_cm_segment, axis = 0).astype(np.int16)\n",
    "        sum_cm = np.sum(outer_cm_segment, axis = 0).astype(np.int16)\n",
    "        plot_cm(avg_cm)\n",
    "        plot_cm(sum_cm)\n",
    "        print('        Video-level CM: \\n')\n",
    "        avg_cm = np.mean(outer_cm_video, axis = 0).astype(np.int16)\n",
    "        sum_cm = np.sum(outer_cm_video, axis = 0).astype(np.int16)\n",
    "        plot_cm(avg_cm)  \n",
    "        plot_cm(sum_cm)\n",
    "        roc_combined(tprs, aucs, mean_fpr, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "162b336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment1(timestep): \n",
    "    # load OpenFace data from R \n",
    "    path1 = 'data/expt1_of.csv'\n",
    "    of_data = load_OF_data(path1)\n",
    "    \n",
    "    # load FaceReader data from R \n",
    "    path2 = 'data/expt1_fr.csv'\n",
    "    fr_data = load_FR_data(path2)\n",
    "    \n",
    "    # load survey data\n",
    "    path3 = 'data/startups.csv'\n",
    "    survey_data = load_survey_data(path3)\n",
    "    \n",
    "    # number of features for models\n",
    "    features = of_data.shape[1] - 2\n",
    "    \n",
    "    # access index and pinv columns from survey data \n",
    "    index, pinv = survey_process(survey_data)\n",
    "    \n",
    "    # get parameter grid for HP tuning \n",
    "    grid = parameter_grid(timestep, features)\n",
    "    \n",
    "    # initialise GridSearchCV object\n",
    "    gridcvs, inner_cv = grid_search_objects(grid)\n",
    "      \n",
    "    # perform nested k-fold cross validation for OpenFace data\n",
    "    print('\\n', 50 * '-', ' FOR OPENFACE DATA ', 50 * '-')\n",
    "    nested_stratifiedKfold(index, pinv, of_data, gridcvs, inner_cv, timestep)\n",
    "        \n",
    "    # perform nested k-fold cross validation for FaceReader data\n",
    "    print('\\n', 50 * '-', ' FOR FACEREADER DATA ', 50 * '-')\n",
    "    nested_stratifiedKfold(index, pinv, fr_data, gridcvs, inner_cv, timestep)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f265d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment2(timestep): \n",
    "    # load OpenFace data from R \n",
    "    path1 = 'data/expt2_of.csv'\n",
    "    of_data = load_OF_data(path1)\n",
    "    \n",
    "    # load FaceReader data from R \n",
    "    path2 = 'data/expt2_fr.csv'\n",
    "    fr_data = load_FR_data(path2)\n",
    "    \n",
    "    # load survey data\n",
    "    path3 = 'data/startups.csv'\n",
    "    survey_data = load_survey_data(path3)\n",
    "    \n",
    "    # number of features for models\n",
    "    features = of_data.shape[1] - 2\n",
    "    \n",
    "    # access index and pinv columns from survey data \n",
    "    index, pinv = survey_process(survey_data)\n",
    "    \n",
    "    # get parameter grid for HP tuning \n",
    "    grid = parameter_grid(timestep, features)\n",
    "    \n",
    "    # initialise GridSearchCV object\n",
    "    gridcvs, inner_cv = grid_search_objects(grid)\n",
    "      \n",
    "    # perform nested k-fold cross validation for OpenFace data\n",
    "    print('\\n', 50 * '-', ' FOR OPENFACE DATA ', 50 * '-')\n",
    "    nested_stratifiedKfold(index, pinv, of_data, gridcvs, inner_cv, timestep)\n",
    "        \n",
    "    # perform nested k-fold cross validation for FaceReader data\n",
    "    print('\\n', 50 * '-', ' FOR FACEREADER DATA ', 50 * '-')\n",
    "    nested_stratifiedKfold(index, pinv, fr_data, gridcvs, inner_cv, timestep)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84bfa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment3(timestep): \n",
    "    # load OpenFace data from R \n",
    "    path1 = 'data/expt3_of.csv'\n",
    "    of_data = load_OF_data(path1)\n",
    "    \n",
    "    # load FaceReader data from R \n",
    "    path2 = 'data/expt3_fr.csv'\n",
    "    fr_data = load_FR_data(path2)\n",
    "    \n",
    "    # load survey data\n",
    "    path3 = 'data/startups.csv'\n",
    "    survey_data = load_survey_data(path3)\n",
    "    \n",
    "    # number of features for models\n",
    "    features = of_data.shape[1] - 2\n",
    "    \n",
    "    # access index and pinv columns from survey data \n",
    "    index, pinv = survey_process(survey_data)\n",
    "    \n",
    "    # get parameter grid for HP tuning \n",
    "    grid = parameter_grid(timestep, features)\n",
    "    \n",
    "    # initialise GridSearchCV object\n",
    "    gridcvs, inner_cv = grid_search_objects(grid)\n",
    "      \n",
    "    # perform nested k-fold cross validation for OpenFace data\n",
    "    print('\\n', 50 * '-', ' FOR OPENFACE DATA ', 50 * '-')\n",
    "    nested_stratifiedKfold(index, pinv, of_data, gridcvs, inner_cv, timestep)\n",
    "        \n",
    "    # perform nested k-fold cross validation for FaceReader data\n",
    "    print('\\n', 50 * '-', ' FOR FACEREADER DATA ', 50 * '-')\n",
    "    nested_stratifiedKfold(index, pinv, fr_data, gridcvs, inner_cv, timestep)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715df46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment4(timestep): \n",
    "    # load OpenFace data from R \n",
    "    path1 = 'data/expt4_of.csv'\n",
    "    of_data = load_OF_data(path1)\n",
    "    \n",
    "    # load FaceReader data from R \n",
    "    path2 = 'data/expt4_fr.csv'\n",
    "    fr_data = load_FR_data(path2)\n",
    "    \n",
    "    # load survey data\n",
    "    path3 = 'data/startups.csv'\n",
    "    survey_data = load_survey_data(path3)\n",
    "    \n",
    "    # number of features for models\n",
    "    features = of_data.shape[1] - 2\n",
    "    \n",
    "    # access index and pinv columns from survey data \n",
    "    index, pinv = survey_process(survey_data)\n",
    "    \n",
    "    # get parameter grid for HP tuning \n",
    "    grid = parameter_grid(timestep, features)\n",
    "    \n",
    "    # initialise GridSearchCV object\n",
    "    gridcvs, inner_cv = grid_search_objects(grid)\n",
    "      \n",
    "    # perform nested k-fold cross validation for OpenFace data\n",
    "    print('\\n', 50 * '-', ' FOR OPENFACE DATA ', 50 * '-')\n",
    "    nested_stratifiedKfold(index, pinv, of_data, gridcvs, inner_cv, timestep)\n",
    "        \n",
    "    # perform nested k-fold cross validation for FaceReader data\n",
    "    print('\\n', 50 * '-', ' FOR FACEREADER DATA ', 50 * '-')\n",
    "    nested_stratifiedKfold(index, pinv, fr_data, gridcvs, inner_cv, timestep)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae960bc",
   "metadata": {},
   "source": [
    "### Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "755e65c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# feature Set 1\n",
    "experiment1(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6da3b5",
   "metadata": {},
   "source": [
    "### Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "020df31a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# feature Set 2\n",
    "experiment2(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849df91b",
   "metadata": {},
   "source": [
    "### Experiment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d60684e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# feature Set 3\n",
    "experiment3(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e553fc",
   "metadata": {},
   "source": [
    "### Experiment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cbf24217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature Set 4\n",
    "experiment4(100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
